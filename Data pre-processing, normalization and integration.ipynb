{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Onedot task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGxBk6Q81kaIF677afSlqU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW_6wydeeWWK"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openpyxl as pxl\n",
        "\n",
        "# load data\n",
        "data = pd.read_json ('/content/supplier_car.json', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install XlsxWriter"
      ],
      "metadata": {
        "id": "DMTv-r4z95pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Step Pre-processing"
      ],
      "metadata": {
        "id": "-zvsFSP7ECFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sort data for pre-processing\n",
        "sorted_data = data.sort_values(['ID', 'Attribute Names'])\n",
        "s_d = sorted_data\n",
        "s_d = s_d.drop(labels = ['entity_id', 'ModelTypeText', 'TypeNameFull', 'ModelText'], axis = 1)\n",
        "s_d = s_d.rename(columns={\"MakeText\" : \"make\", 'TypeName': 'model'})"
      ],
      "metadata": {
        "id": "hP5ggJgDBp4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add a row for the Harley-Davidson\n",
        "HDrow = {'ID': 824, 'make': 'HARLEY-DAVIDSON', 'model': 'HPU Hurricane TC', 'Attribute Names': 'BodyTypeText', 'Attribute Values': 'Motocycle'}\n",
        "s_d = s_d.append(HDrow, ignore_index = True)"
      ],
      "metadata": {
        "id": "0B6dM08cobld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the colnames variable that contains column names\n",
        "colnames = s_d['Attribute Names'].unique()\n",
        "colnames = colnames.tolist()\n",
        "colnames.insert(0,'model')\n",
        "colnames.insert(0,'make')\n",
        "colnames.insert(0,'ID')"
      ],
      "metadata": {
        "id": "AucR_dchJO90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-process data and input these data in a new dataframe\n",
        "# new dataframe creation\n",
        "new_dataframe = pd.DataFrame(data = None, columns = colnames)\n",
        "n_d = new_dataframe\n",
        "# creation of the colnames_2 variable that equals colnames except 3 columns names\n",
        "colnames_2 = colnames\n",
        "colnames_2.remove('ID')\n",
        "colnames_2.remove('make')\n",
        "colnames_2.remove('model')\n",
        "# index creation\n",
        "for i in s_d['ID'].unique() :\n",
        "  index = s_d['ID'] == i\n",
        "  indexed_data = s_d[index]\n",
        "  i_d = indexed_data\n",
        "  # first dataframe line\n",
        "  if n_d.shape[0] == 0 :\n",
        "   # first 3 columns\n",
        "   n_d['ID'] = i_d['ID'].unique()\n",
        "   n_d['make'] = i_d['make'].unique()\n",
        "   n_d['model'] = i_d['model'].unique()\n",
        "   # remaining columns\n",
        "   for j in colnames_2 :\n",
        "     i = i\n",
        "     jndex = i_d['Attribute Names'] == j\n",
        "     jndexed_data = i_d[jndex]\n",
        "     j_d = jndexed_data\n",
        "     n_d[j].iloc[i-1] = j_d['Attribute Values'].unique()\n",
        "  # following dataframe lines\n",
        "  else  :\n",
        "   # first 3 columns\n",
        "   n_d['ID'].iloc[-1] = i_d['ID'].unique()\n",
        "   n_d['make'].iloc[-1] = i_d['make'].unique()\n",
        "   n_d['model'].iloc[-1] = i_d['model'].unique()\n",
        "   # remaining columns\n",
        "   for j in colnames_2 :\n",
        "     i = i\n",
        "     jndex = i_d['Attribute Names'] == j\n",
        "     jndexed_data = i_d[jndex]\n",
        "     j_d = jndexed_data\n",
        "     n_d[j].iloc[i-1] = j_d['Attribute Values'].unique()\n",
        "  n_d = n_d.append(new_dataframe, ignore_index = True) \n",
        "n_d = n_d.drop(axis = 0, index = 1153)\n",
        "#n_d"
      ],
      "metadata": {
        "id": "RXE2-iTwGlDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing brackets from strings within the dataframe\n",
        "n_d = n_d.astype(str)\n",
        "x = 1153\n",
        "y = 22\n",
        "arr = np.zeros((x, y), dtype=int)\n",
        "colnames.insert(0,'model')\n",
        "colnames.insert(0,'make')\n",
        "colnames.insert(0,'ID')\n",
        "n_d_2 = pd.DataFrame(data = arr, columns = colnames)\n",
        "for k in colnames :\n",
        "  n_d_2[k] = n_d[k].str.strip(\"[']\")\n",
        "#n_d_2"
      ],
      "metadata": {
        "id": "5WjhbXsjejfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Step Normalization"
      ],
      "metadata": {
        "id": "IqhyyftyEJcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Target data\n",
        "df = pd.read_excel ('/content/Target Data.xlsx')"
      ],
      "metadata": {
        "id": "nV4ZESozEm7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize conditions in pre-processed data\n",
        "n_d_2['ConditionTypeText'].unique()"
      ],
      "metadata": {
        "id": "5gFyXK5YwRIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize conditions in target data\n",
        "df['condition'].unique()"
      ],
      "metadata": {
        "id": "uxVDD2LLwHS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data normalisation for new & used, other labeling have to be discussed with the customer\n",
        "n_d_3 = n_d_2.replace(to_replace=['Occasion', 'Neu'], value=['Used', 'New'], inplace=False)\n",
        "n_d_3['ConditionTypeText'].unique()"
      ],
      "metadata": {
        "id": "S_b2Lns2Em0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb1478e-ce15-404e-a43c-d9829702ec83"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Used', 'Oldtimer', 'New', 'Vorf√ºhrmodell'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Step Integration"
      ],
      "metadata": {
        "id": "k9xJuE1EEOH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename the BodyTypeText column \n",
        "n_d_3_2 = n_d_3.rename(columns = {'BodyTypeText':'carType'}, inplace = False)\n",
        "#n_d_3_2.head()"
      ],
      "metadata": {
        "id": "K1JURo8hESG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the carType column from the normalized data as the first column\n",
        "n_d_3_2 = n_d_3_2[['carType'] + [l for l in n_d_3_2 if l not in ['carType']]]\n",
        "#n_d_3_2.head()"
      ],
      "metadata": {
        "id": "Zv4Md5z5HgKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# join the target and normalized dataframes\n",
        "n_d_4 = pd.concat([df, n_d_3_2])\n",
        "n_d_4 = n_d_4.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "GkgVCSb5HPkX"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export datasheets to an excel file\n",
        "with pd.ExcelWriter('/content/Deliverable Hugo JOHAN.xlsx', engine='xlsxwriter') as writer:\n",
        "   n_d_2.to_excel(writer, sheet_name='Pre-processed data', index=False)\n",
        "   n_d_3.to_excel(writer, sheet_name='Normalized supplier data', index=False)\n",
        "   n_d_4.to_excel(writer, sheet_name='Integrated supplier data', index=False)"
      ],
      "metadata": {
        "id": "etcPsDYy7eT_"
      },
      "execution_count": 111,
      "outputs": []
    }
  ]
}